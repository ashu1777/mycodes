RHEL-8 EXAM MODEL PAPER    Duration: 4Hrs

Instructions:

Control Node: worstation.lab.example.com

Manage Node: servera.lab.example.com,serverb.lab.example.com,serverc.lab.example.com,serverd.lab.example.com

* All node root password is 'redhat' and login as student user

* Create a directory 'ansible' under the path /home/student and all the playbook should be under /home/student/ansible

* create a playbook as student user and remote user name is devops
_______________________________________________________________________	

# ssh root@workstation

# su - student 


1. Create a static inventory file name inventory under /home/student/ansible.
  
    • Create a inventory group called dev and servera.lab.example.com hosts should be member of that group.
    • Create a inventory group called test and serverb.lab.example.com hosts should be member of that group.
    • Create a inventory group called prod and serverc.lab.example.com hosts should be member of that group
    • Create a inventory group called balancers and serverd.lab.example.com hosts should be member of that group
    • Create a Nested inventory group called webservers and prod group should be children of that group

    [dev]
    servera.lab.example.com
    [test]
    serverb.lab.example.com
    [prod]
    serverc.lab.example.com
    [balancers]
    serverd.lab.example.com
    [webservers:children]
    prod	

# mkdir /home/student/ansible

# cd /home/student/ansible

# vi inventory

[dev]
servera.lab.example.com
[test]
serverb.lab.example.com
[prod]
serverc.lab.example.com
[balancers]
serverd.lab.example.com
[webservers:children]
prod

2) Install ansible package and create a ansible.cfg file
i) ansible.cfg file should be pointed with inventory and roles path(/home/student/ansible/roles)

# sudo yum install ansible vim tree -y

# vim .vimrc
 set ai ts=2 et cursorcolumn

# source .vimrc


# vim /home/student/ansible/ansible.cfg

[defaults]
remote_user=devops
inventory=/home/student/ansible/inventory
roles_path=/home/student/ansible/roles

[privilege_escalation]
become=true

# ansible all -a id
(you should get the root user as output)

3. Create a shell script adhoc.sh for configuring repository in all nodes.

  i) Name=baseos
  Description=Baseos Description
  Url = http://content/rhel8.0/x86_64/dvd/BaseOS
  GPG is enabled.
  Gpgkey = http://content.example.com/rhel8.0/x86_64/dvd/RPM-GPG-KEY-redhat-release
  Repository is enabled.

  ii) Name = appstream
  Description = App Description
  Url = http://content/rhel8.0/x86_64/dvd/AppStream
  GPG is enabled.
  Gpgkey = http://content.example.com/rhel8.0/x86_64/dvd/RPM-GPG-KEY-redhat-release
  Repository is enabled.

# vim /home/student/ansible/adhoc.sh

#!/bin/sh 
ansible all -m yum_repository -a 'name="baseos" description="baseos description" baseurl=http://content/rhel8.0/x86_64/dvd/BaseOS/ gpgcheck=yes gpgkey=http://content.example.com/rhel8.0/x86_64/dvd/RPM-GPG-KEY-redhat-release enabled=yes'

ansible all -m yum_repository -a 'name="appstream" description="app description" baseurl=http://content/rhel8.0/x86_64/dvd/AppStream/ gpgcheck=yes gpgkey=http://content.example.com/rhel8.0/x86_64/dvd/RPM-GPG-KEY-redhat-release enabled=yes'

# chmod 755 adhoc.sh

# ./adhoc.sh

4. create a directory 'roles' under /home/student/ansible .

  i)   Playbook name requirements.yml under roles directory and download the roles using galaxy command under it.
  ii)  Roles name should be balancer and download using this url http://content.example.com/rhce/balancer.tgz.
  iii) Phpinfo roles download using this url http://content.example.com/rhce/phpinfo.tgz.


# mkdir /home/student/ansible/roles

# vim /home/student/ansible/requirements.yml
---
- src: http://content.example.com/Rhce/balancer.tgz
  name: balancer
- src: http://content.example.com/Rhce/phpinfo.tgz
  name: phpinfo

# ansible-galaxy install -r /home/student/ansible/requirements.yml -p roles

5. Create offline role named apache under roles directory.

  i)   Install httpd package and start and enable the httpd service.
  ii)  Host the web page using the template.j2 and it should contain "My host is {{ FQDN }} on {{ IPADDRESS }}".
  iii) Create a playbook named apache_role.yml and run the role in dev group.


# ansible-galaxy init roles/apache 


# vim /home/student/ansible/roles/apache/templates/template.j2

My host is {{ ansible_fqdn }} on {{ansible_default_ipv4.address}}

# vim /home/student/ansible/roles/apache/tasks/main.yml 

- name: install httpd package
  yum:
    name: 
      - httpd
      - firewalld
    state: present
- name: start service httpd
  service:
    name: httpd
    state: started
    enabled: yes
- name: start service firewalld
  service:
    name: firewalld
    state: started
    enabled: yes
- name: firewall rule
  firewalld:
    service: http
    state: enabled
    permanent: true
    immediate: yes
- template:
    src: template.j2
    dest: /var/www/html/index.html

# vim /home/student/ansible/apache_role.yml
---
- name: apache deploy
  hosts: dev
  roles:
    - apache

# ansible-playbook  apache_role.yml

# curl servera.lab.example.com (verify the output)

6. Create a playbook called roles.yml and it should run balancer and phpinfo roles.

  i)  Run the balancer role on test group.
  ii) Phpinfo role on dev group.

  
# vim /home/student/ansible/roles.yml
---
- name: 
  hosts: dev
  roles:
    - phpinfo
- name:
  hosts: test
  roles:
    - balancer

# ansible-playbook  roles.yml 

7. Install system related roles and the playbook name timesync.yml and it should use "rhel-system-roles.timesync" role.

  i)  Use ntp server classroom.example.com and enable iburst.
  ii) Run this playbook on all the managed nodes. 

# sudo yum install rhel-system-roles  -y 

# vim /home/student/ansible/timesync.yml
---
- name: timesync
  hosts: all
  vars:
    timesync_ntp_servers:
      - hostname: classroom.example.com
        iburst: yes
  roles:
    - /usr/share/ansible/roles/rhel-system-roles.timesync

# ansible-playbook timesync_playbook.yml

8. Install packages in multiple group.

  i)   php and mariadb-server in dev and test group.
  ii)  "Development Tools" group package in prod group.
  iii) Update all packages in dev group.
  iv)  Use separate play for each task and playbook name should be packages.yml.

# vim /home/student/ansible/packages.yml
---
- name: package installation
  hosts: dev,test
  tasks:
  - name: install php and mariadb
    yum:
      name:
        - php
        - mariadb-server
      state: present 

- name: group installin of RPM Development tools
  hosts: prod
  tasks:
  - name: installing group package
    yum:
      name: '@Development Tools' (in exam @RPM Development Tools)
      state: present

- name: update packages in the dev groups
  hosts: dev
  tasks:
  - name: updating all the packages in dev 
    yum:
      name: '*'
      state: latest

# ansible-playbook packages.yml

9. Create playbook webcontent.yml and it should run on dev group.

  i)   Create directory /webdev and it should be owned by devops group.
  ii)  /webdev directory type should be "httpd" and Assing permission 2775.
  iii) Create index.html under /webdev and the index.html file should have the content "Developement".
  iv)  Link the /webdev directory to /var/www/html/webdev. 

# vim /home/student/ansible/webcontent.yml
---
- name: create a link 
  hosts: dev
  tasks:
  - name: create a directory
    file:                
      path: /webdev
      state: directory
      group: devops
      mode: 02775
      setype: httpd_sys_content_t	
  - name: create a file
    file:
      path: /webdev/index.html
      state: touch
  - name: copy the contents
    copy:
      content: |
	Development
      dest: /webdev/index.html 
  - name: link a file
    file:
      src: /webdev
      dest: /var/www/html/webdev
      state: link
      
# ansible-playbook webcontent.yml

# curl servera.lab.example.com/webdev/

10. Collect hardware report using playbook in all nodes.

  i)  Download hwreport.txt from the url http://content.example.com/Rhce/hwreport.txt and save it under /root.

  /root/hwreport.txt should have the content with node informations as key=value.
  
 #hwreport
  HOSTNAME:
  MEMORY:
  BIOS:
  CPU:
  VDA_DISK_SIZE:
  VDB_DISK_SIZE:

  ii)  If there no information it have to show "None".
  iii) playbook name should be hwreport.yml.
  
# vim /home/student/ansible/hwreport.yml	
---
- name: hwreport
  hosts: all
  ignore_errors: yes
  tasks:
  - name: test php page is installed
    get_url:
      url: "http://content.example.com/Rhce/hwreport.txt"
      dest: /root/hwreport.txt
  - name: collect report
    set_fact:
	HOSTNAME: "{{ ansible_hostname }}"
        MEMORY: "{{ ansible_memtotal_mb  }}"
        BIOS: "{{ ansible_bios_version }}"
        CPU: "{{ ansible_processor }}"
        VDA_DISK_SIZE: "{{ ansible_devices['vda']['size'] }}"
  - name: collect report
    set_fact:
        VDB_DISK_SIZE: "{{ ansible_devices['vdb']['size'] }}"
  - name: copy the varialbes
    copy:
      content:  |
        #hwreport
	 HOSTNAME={{ HOSTNAME | default('NONE') }}
         MEMORY={{ MEMORY | default('NONE') }}
         BIOS={{ BIOS  | default('NONE') }}
         CPU={{ CPU | default('NONE') }}
         VDA_DISK_SIZE={{ VDA_DISK_SIZE | default('NONE') }}
         VDB_DISK_SIZE={{ VDB_DISK_SIZE | default('NONE') }}
      dest: /root/hwreport.txt

# ansible-playbook hwreport.yml

 
11. Replace the file /etc/issue on all managed nodes.

  i)   In dev group /etc/issue should be "Developement".
  ii)  In test group /etc/issue should be "Test".
  iii) In prod group /etc/issue should be "Production".
  iv)  Playbook name issue.yml and run in all managed nodes.

# vim /home/student/ansible/issue.yml

---
- name: play for replace module
  hosts: all
  tasks:
  - name: replace the content
    replace:
      path: /etc/issue
      regexp: '\\S[\S\n](?P<Kernel>.*?)?m'
      replace: Test
      dest: /etc/issue
    when: inventory_hostname in groups['test']
  - name: replace the content
    replace:
      path: /etc/issue
      regexp: '\\S[\S\n](?P<Kernel>.*?)?m'
      replace: Development
      dest: /etc/issue
    when: inventory_hostname in groups['dev']
  - name: replace the content
    replace:
      path: /etc/issue
      regexp: '\\S[\S\n](?P<Kernel>.*?)?m'
      replace: Production
      dest: /etc/issue
    when: inventory_hostname in groups['prod']

# ansible-playbook issue.yml

12. Download the file http://content.example.com/Rhce/myhosts.j2

  i) myhosts.j2 is having the content.

  127.0.0.1 localhost.localdomain localhost
  192.168.0.1 localhost.localdomain localdomain

  ii) file should collect all node information like ipaddress,fqdn,hostname but it is already located in the file of /etc/hosts, so we should store the all node 
information in /etc/myhosts playbook run in all the managed node.

  hosts file should contains like.
  127.0.0.1 localhost.localdomain localhost
  192.168.0.1 localhost.localdomain localdomain

  172.25.250.10 servera.lab.example.com servera
  172.25.250.11 serverb.lab.example.com serverb
  172.25.250.12 serverc.lab.example.com serverc
  172.25.250.13 serverd.lab.example.com serverd

  iii) playbook name hosts.yml and run in only dev group.

# wget http://content.example.com/Rhce/myhosts.j2

# vim /home/student/ansible/myhosts.j2

last line:
{% for host in groups['all'] %}
{{hostvars[host] ['ansible_facts'] ['default_ipv4'] ['address']}} {{hostvars[host] ['ansible_facts'] ['fqdn']}} {{hostvars[host] ['ansible_facts'] ['hostname']}}
{% endfor %}

# vim hosts.yml
---
- name: jinja2
  hosts: all
  tasks:
  - name: call the template
    template:
      src: myhosts.j2
      dest: /etc/myhosts  
    when: inventory_hostname in groups['dev']

# ansible-playbook hosts.yml

13. Create a variable file vault.yml and that file should contains the variable and vaules.

  pw_manager: lammgr
  pw_developer: lamdev

 i)   vault.yml file should be encrpted using the password "P@sswOrd".
 ii)  Store the password in secret.txt file and which is used for encrypt the variable file.

# vim secret.txt
P@sswOrd

# ansible-vault create vault.yml --vault-password-file=secret.txt

pw_manager: lammgr
pw_developer: lamdev

# ansible-vault view vault.yml --vault-password-file=secret.txt

14. Download the variable file http://content.example.com/Rhce/user_list.yml.

  i)   Playbook name users.yml and run in all nodes using two variable files.
  ii)  Create user and Assign a password as hashed using SHA512.
  iii) Create a group devops and manager.
  iv)  if job == developer it should add the user and they need to add devops group in dev and test group.
  v)   if job == manager it should add the user and they need to add manager group in test group.
  vi)  Use when condition for each play.

# wget http://content.example.com/Rhce/user_list.yml

# vim users.yml
---
- name: install users
  hosts: all
  vars_files:
    - user_list.yml
    - vault.yml
  tasks:
  - name: group install
    group:
      name: devops
      state: present
    when: inventory_hostname in groups['dev'] or inventory_hostname in groups['test']
  - name: group install
    group:
      name: manager
      state: present
    when: inventory_hostname in groups['test']
  - name: useradd
    user:
      name: "{{ item.name }}"
      state: present
      groups: devops
      password: "{{ pw_developer | password_hash('sha512') }}"
    loop:
      "{{  users }}"
    when: item.job == "developer" and  (inventory_hostname in groups['dev'] or inventory_hostname in groups['test'])
  - name: module for adding users in the groups
    user:
      name: "{{ item.name }}"
      state: present
      groups: manager
      password: "{{ pw_manager | password_hash('sha512') }}"
    loop:
      "{{  users }}"
    when: item.job == "manager" and inventory_hostname in groups['test']

# ansible-playbook users.yml --vault-password-file=secret.txt

15. Rekey the variable file from http://content.example.com/Rhce/solaris.yml.

  i)  Old password: vectra
  ii) New password: redhat

# wget http://content.example.com/rhce/solaris.yml
# ansible-vault rekey solaris.yml

Old password: 

New password: 

# ansible-vault view solaris.yml --ask-vault-pass (verify the password)


16. Create a logical volume name data of 1500M from the research volume group and if 1500M size not exits atleast it should have create 800M size.

  i)   debug msg "vg not found" if vg not exist.
  ii)  1500M size is not created it have to debug msg "insufficient size of vg".
  iii) If volume is created format it using ext3 file system.
  iv)  playbook name lvm.yml and run the playbook in all nodes.

# wget http://content/Rhce/initialscripts.sh

# chmod +x initialscripts.sh

# sudo ./initialscripts.sh

* Above commands not for exam 

# vim lvm.yml

---
- name: lvm creation
  hosts: all
  ignore_errors: yes
  tasks:
    - name: vgdisplay
      shell:
        cmd : vgdisplay research
      register: vginfo
    - debug:
        var: vginfo
    - debug:
        msg: "vg research is not found"
      when: vginfo is failed
    - name: lvcraete_1
      lvol:  
        vg: research
        lv: data
        size: 1500m
      when: vginfo is success
      register: vg2
    - debug:
        msg: "Insufficient size of vg"
      when: vg2 is failed
    - name: lvcreate_2
      lvol: 
        vg: research
        lv: data
        size: 800m
      when: vg2 is failed
    - name: file
      filesystem:
        dev: /dev/research/data
	fstype: ext3
	force: yes

# ansible-playbook lvm.yml                                                                                  
